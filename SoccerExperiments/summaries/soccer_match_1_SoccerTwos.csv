Steps,Policy/Entropy,Environment/Episode Length,Self-play/ELO,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,3.2957387,546.3,1199.9022793037204,-0.03189858,-0.07907301849789089,-0.07907301849789089,1.0
20000,3.2957335,519.6666666666666,1199.5724165017193,-0.020285511,-0.0232632787604081,-0.0232632787604081,1.0
30000,3.2932632,593.1111111111111,1200.5484566100902,0.0037341907,0.010277341393863453,0.010277341393863453,1.0
40000,3.2928393,564.125,1201.1016448262371,0.0043204287,-0.10999697797438678,-0.10999697797438678,1.0
50000,3.2897556,545.4,1201.5861093121916,0.008860968,0.09403512979808606,0.09403512979808606,1.0
60000,3.2881715,534.6666666666666,1202.762043834936,0.0040366035,0.10722222593095568,0.10722222593095568,1.0
70000,3.286051,437.75,1200.6565507290982,0.008418106,-0.2569166421890259,-0.2569166421890259,1.0
80000,3.2843378,506.77777777777777,1199.6471855633106,0.008137984,-0.08385795041134483,-0.08385795041134483,1.0
90000,3.2825687,573.7777777777778,1200.341100796801,0.0037298962,-0.10372471108156092,-0.10372471108156092,1.0
100000,3.2810256,470.54545454545456,1200.1378050890805,-0.00014058902,-0.06693866578015414,-0.06693866578015414,1.0
110000,3.27103,599.0,1199.6863594985693,-0.0020625766,0.0,0.0,1.0
120000,3.2681527,564.7777777777778,1200.9957205182552,-0.0035534452,0.05703965822855631,0.05703965822855631,1.0
130000,3.266324,517.0,1201.1113193198398,-0.0058433106,-0.08766314230467144,-0.08766314230467144,1.0
140000,3.2638655,599.0,1202.635902471231,-0.005696633,0.013589038568384507,0.013589038568384507,1.0
150000,3.2608013,546.4444444444445,1202.734849458396,-0.004757544,0.087666564517551,0.087666564517551,1.0
160000,3.256619,552.3333333333334,1204.1538939539107,-0.005143255,0.07777750492095947,0.07777750492095947,1.0
170000,3.258936,581.125,1204.0136197117279,-0.0038362145,-0.11764705882352941,-0.11764705882352941,1.0
180000,3.2539515,551.0,1203.4849434933828,0.0015711496,-0.026561573932045383,-0.026561573932045383,1.0
